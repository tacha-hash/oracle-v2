/**
 * Oracle v2 Indexer
 *
 * Parses markdown files from ψ/memory and creates:
 * 1. SQLite index (source of truth for metadata)
 * 2. Chroma vectors (semantic search)
 *
 * Following claude-mem's granular vector pattern:
 * - Split large documents into smaller chunks
 * - Each principle/pattern becomes multiple vectors
 * - Enable concept-based filtering
 *
 * Uses chroma-mcp (Python) via MCP protocol for embeddings.
 * This avoids pnpm/npm dynamic import issues with chromadb-default-embed.
 */

import fs from 'fs';
import path from 'path';
import { Database } from 'bun:sqlite';
import { ChromaMcpClient } from './chroma-mcp.js';
import type { OracleDocument, OracleMetadata, IndexerConfig } from './types.js';

// Category definitions for knowledge graph visualization
export type KnowledgeCategory =
  | 'philosophy'    // ปรัชญา - oracle principles, nothing-deleted, form-and-formless
  | 'technical'     // เทคนิค - api, debugging, installation, tools
  | 'ai-tools'      // เครื่องมือ AI - kie.ai, flux, seedance
  | 'identity'      // ตัวตน - le, arthur, oracle-family, origin-story
  | 'projects'      // โปรเจค - oracle-v2, louracle, storyboard
  | 'retrospective' // บันทึก - session, milestone
  | 'methodology'   // วิธีทำงาน - vibecoding, multi-agent, delegation
  | 'ethics';       // จริยธรรม - ai-ethics, transparency, safety

// Concept-to-category mapping
const CATEGORY_MAPPINGS: Record<KnowledgeCategory, string[]> = {
  philosophy: [
    'oracle-philosophy', 'philosophy', 'nothing-deleted', 'form-and-formless',
    'kalama-sutta', 'mother-child', 'dialogue', 'questioning', 'emergence',
    'civilization-mirror', 'external-brain', 'patterns', 'meta-learning',
    'distributed-consciousness', 'growth', 'learning'
  ],
  technical: [
    'api', 'debugging', 'installation', 'troubleshooting', 'path-issues',
    'macos', 'cli-tools', 'ghq', 'symlink', 'github', 'gh-cli', 'security',
    'endpoint-pattern', 'git', 'code', 'file', 'config', 'test', 'debug',
    'error', 'fix', 'refactor'
  ],
  'ai-tools': [
    'kie.ai', 'flux-kontext', 'seedance', 'image-generation', 'video-generation',
    'haiku', 'claude', 'mcp', 'ai-assisted'
  ],
  identity: [
    'le', 'louis', 'arthur', 'oracle-family', 'origin-story', 'le-birth',
    'louis-profile', 'identity', 'first-contact', 'first-meeting', 'louracle',
    'nats-brain-oracle'
  ],
  projects: [
    'oracle-v2', 'storyboard-web', 'project-management', 'incubate',
    'oracle-pattern', 'contribution', 'project', 'yupp', 'gesture-dj',
    'kie-ai', 'oracle-visualizer', 'sales-tracker', 'mediapipe', 'seedance',
    'flux-kontext', 'deployment', 'railway', 'vercel'
  ],
  retrospective: [
    'retrospective', 'first-session', 'full-session', 'milestone', 'session',
    'exploration'
  ],
  methodology: [
    'vibecoding', 'multi-agent', 'best-practice', 'delegation', 'cost-efficiency',
    'pattern', 'workflow', 'plan', 'task', 'issue', 'feature', 'ai-collaboration'
  ],
  ethics: [
    'ai-ethics', 'ethics', 'transparency', 'privacy', 'ai-human-trust',
    'responsibility', 'partnership', 'ai-safety', 'power-concentration',
    'decentralization', 'federated-learning'
  ]
};

/**
 * Classify document into a category based on its concepts
 * Returns the category with most matching concepts
 */
function classifyCategory(concepts: string[]): KnowledgeCategory {
  const scores: Record<KnowledgeCategory, number> = {
    philosophy: 0,
    technical: 0,
    'ai-tools': 0,
    identity: 0,
    projects: 0,
    retrospective: 0,
    methodology: 0,
    ethics: 0
  };

  for (const concept of concepts) {
    const lowerConcept = concept.toLowerCase();
    for (const [category, keywords] of Object.entries(CATEGORY_MAPPINGS)) {
      if (keywords.some(k => lowerConcept.includes(k) || k.includes(lowerConcept))) {
        scores[category as KnowledgeCategory]++;
      }
    }
  }

  // Find category with highest score
  let maxScore = 0;
  let bestCategory: KnowledgeCategory = 'methodology'; // default

  for (const [category, score] of Object.entries(scores)) {
    if (score > maxScore) {
      maxScore = score;
      bestCategory = category as KnowledgeCategory;
    }
  }

  return bestCategory;
}

export class OracleIndexer {
  private db: Database;
  private chromaClient: ChromaMcpClient | null = null;
  private config: IndexerConfig;

  constructor(config: IndexerConfig) {
    this.config = config;
    this.db = new Database(config.dbPath);
    this.initDatabase();
  }

  /**
   * Initialize SQLite schema
   */
  private initDatabase(): void {
    this.db.exec(`
      CREATE TABLE IF NOT EXISTS oracle_documents (
        id TEXT PRIMARY KEY,
        type TEXT NOT NULL,
        source_file TEXT NOT NULL,
        concepts TEXT NOT NULL,
        category TEXT,
        created_at INTEGER NOT NULL,
        updated_at INTEGER NOT NULL,
        indexed_at INTEGER NOT NULL
      );

      CREATE INDEX IF NOT EXISTS idx_type ON oracle_documents(type);
      CREATE INDEX IF NOT EXISTS idx_source ON oracle_documents(source_file);
      CREATE INDEX IF NOT EXISTS idx_category ON oracle_documents(category);

      -- FTS5 for keyword search (with Porter stemmer for tire/tired matching)
      CREATE VIRTUAL TABLE IF NOT EXISTS oracle_fts USING fts5(
        id UNINDEXED,
        content,
        concepts,
        tokenize='porter unicode61'
      );

      -- Consult log for tracking oracle_consult queries
      CREATE TABLE IF NOT EXISTS consult_log (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        decision TEXT NOT NULL,
        context TEXT,
        principles_found INTEGER NOT NULL,
        patterns_found INTEGER NOT NULL,
        guidance TEXT NOT NULL,
        created_at INTEGER NOT NULL
      );

      CREATE INDEX IF NOT EXISTS idx_consult_created ON consult_log(created_at);

      -- Indexing status for tray app
      CREATE TABLE IF NOT EXISTS indexing_status (
        id INTEGER PRIMARY KEY CHECK (id = 1),
        is_indexing INTEGER NOT NULL DEFAULT 0,
        progress_current INTEGER DEFAULT 0,
        progress_total INTEGER DEFAULT 0,
        started_at INTEGER,
        completed_at INTEGER,
        error TEXT
      );

      -- Ensure single row exists
      INSERT OR IGNORE INTO indexing_status (id, is_indexing) VALUES (1, 0);
    `);
  }

  /**
   * Update indexing status for tray app
   */
  private setIndexingStatus(isIndexing: boolean, current: number = 0, total: number = 0, error?: string): void {
    this.db.prepare(`
      UPDATE indexing_status SET
        is_indexing = ?,
        progress_current = ?,
        progress_total = ?,
        started_at = CASE WHEN ? = 1 AND started_at IS NULL THEN ? ELSE started_at END,
        completed_at = CASE WHEN ? = 0 THEN ? ELSE NULL END,
        error = ?
      WHERE id = 1
    `).run(
      isIndexing ? 1 : 0,
      current,
      total,
      isIndexing ? 1 : 0,
      Date.now(),
      isIndexing ? 1 : 0,
      Date.now(),
      error || null
    );
  }

  /**
   * Main indexing workflow
   */
  async index(): Promise<void> {
    console.log('Starting Oracle indexing...');

    // Set indexing status for tray app
    this.setIndexingStatus(true, 0, 100);

    // Clear existing data to prevent duplicates
    console.log('Clearing existing index data...');
    this.db.exec('DELETE FROM oracle_fts');
    this.db.exec('DELETE FROM oracle_documents');

    // Initialize ChromaMcpClient (uses chroma-mcp Python server)
    try {
      this.chromaClient = new ChromaMcpClient(
        'oracle_knowledge',
        this.config.chromaPath,
        '3.12'  // Python version
      );
      await this.chromaClient.deleteCollection();
      await this.chromaClient.ensureCollection();
      console.log('ChromaDB connected via MCP');
    } catch (e) {
      console.log('ChromaDB not available, using SQLite-only mode:', e instanceof Error ? e.message : e);
      this.chromaClient = null;
    }

    const documents: OracleDocument[] = [];

    // Index each source type
    documents.push(...await this.indexResonance());
    documents.push(...await this.indexLearnings());
    documents.push(...await this.indexRetrospectives());

    // Store in SQLite + Chroma
    await this.storeDocuments(documents);

    // Mark indexing complete
    this.setIndexingStatus(false, documents.length, documents.length);
    console.log(`Indexed ${documents.length} documents`);
    console.log('Indexing complete!');
  }

  /**
   * Index ψ/memory/resonance/ files (identity, principles)
   */
  private async indexResonance(): Promise<OracleDocument[]> {
    const resonancePath = path.join(this.config.repoRoot, this.config.sourcePaths.resonance);
    const files = fs.readdirSync(resonancePath).filter(f => f.endsWith('.md'));
    const documents: OracleDocument[] = [];

    for (const file of files) {
      const filePath = path.join(resonancePath, file);
      const content = fs.readFileSync(filePath, 'utf-8');
      const docs = this.parseResonanceFile(file, content);
      documents.push(...docs);
    }

    console.log(`Indexed ${documents.length} resonance documents from ${files.length} files`);
    return documents;
  }

  /**
   * Parse resonance markdown into granular documents
   * Following claude-mem's pattern of splitting by sections
   * Now reads frontmatter tags and inherits them to all chunks
   */
  private parseResonanceFile(filename: string, content: string): OracleDocument[] {
    const documents: OracleDocument[] = [];
    const sourceFile = `ψ/memory/resonance/${filename}`;
    const now = Date.now();

    // Extract file-level tags from frontmatter
    const fileTags = this.parseFrontmatterTags(content);

    // Split by ### headers (principles, sections)
    const sections = content.split(/^###\s+/m).filter(s => s.trim());

    sections.forEach((section, index) => {
      const lines = section.split('\n');
      const title = lines[0].trim();
      const body = lines.slice(1).join('\n').trim();

      if (!body) return;

      // Main document for this principle/section
      const id = `resonance_${filename.replace('.md', '')}_${index}`;
      const extractedConcepts = this.extractConcepts(title, body);
      const mergedConcepts = this.mergeConceptsWithTags(extractedConcepts, fileTags);
      documents.push({
        id,
        type: 'principle',
        source_file: sourceFile,
        content: `${title}: ${body}`,
        concepts: mergedConcepts,
        category: classifyCategory(mergedConcepts),
        created_at: now,
        updated_at: now
      });

      // Split bullet points into sub-documents (granular pattern)
      const bullets = body.match(/^[-*]\s+(.+)$/gm);
      if (bullets) {
        bullets.forEach((bullet, bulletIndex) => {
          const bulletText = bullet.replace(/^[-*]\s+/, '').trim();
          const bulletConcepts = this.extractConcepts(bulletText);
          const bulletMergedConcepts = this.mergeConceptsWithTags(bulletConcepts, fileTags);
          documents.push({
            id: `${id}_sub_${bulletIndex}`,
            type: 'principle',
            source_file: sourceFile,
            content: bulletText,
            concepts: bulletMergedConcepts,
            category: classifyCategory(bulletMergedConcepts),
            created_at: now,
            updated_at: now
          });
        });
      }
    });

    return documents;
  }

  /**
   * Index ψ/memory/learnings/ files (patterns discovered)
   */
  private async indexLearnings(): Promise<OracleDocument[]> {
    const learningsPath = path.join(this.config.repoRoot, this.config.sourcePaths.learnings);
    if (!fs.existsSync(learningsPath)) return [];

    const files = fs.readdirSync(learningsPath).filter(f => f.endsWith('.md'));
    const documents: OracleDocument[] = [];

    for (const file of files) {
      const filePath = path.join(learningsPath, file);
      const content = fs.readFileSync(filePath, 'utf-8');
      const docs = this.parseLearningFile(file, content);
      documents.push(...docs);
    }

    console.log(`Indexed ${documents.length} learning documents from ${files.length} files`);
    return documents;
  }

  /**
   * Parse learning markdown into documents
   * Now reads frontmatter tags and inherits them to all chunks
   */
  private parseLearningFile(filename: string, content: string): OracleDocument[] {
    const sourceFile = `ψ/memory/learnings/${filename}`;
    const now = Date.now();

    // Extract file-level tags from frontmatter
    const fileTags = this.parseFrontmatterTags(content);

    // Extract title from frontmatter or filename
    const titleMatch = content.match(/^title:\s*(.+)$/m);
    const title = titleMatch ? titleMatch[1].replace(/^#\s*/, '') : filename.replace('.md', '');

    // Clean content (remove frontmatter for display)
    const cleanContent = content.replace(/^---[\s\S]*?---\n*/m, '').trim();

    // Extract first paragraph or summary as label
    const firstPara = cleanContent.split(/\n\n/)[0]?.replace(/^#.*\n/m, '').trim() || title;
    const label = firstPara.slice(0, 100) + (firstPara.length > 100 ? '...' : '');

    // Extract concepts from entire file content
    const extractedConcepts = this.extractConcepts(title, cleanContent);
    const mergedConcepts = this.mergeConceptsWithTags(extractedConcepts, fileTags);

    // One document per file (no section splitting)
    return [{
      id: `learning_${filename.replace('.md', '')}`,
      type: 'learning',
      source_file: sourceFile,
      content: cleanContent.slice(0, 500), // First 500 chars for preview
      label: label,
      concepts: mergedConcepts,
      category: classifyCategory(mergedConcepts),
      created_at: now,
      updated_at: now
    }];
  }

  /**
   * Index ψ/memory/retrospectives/ files (session history)
   */
  private async indexRetrospectives(): Promise<OracleDocument[]> {
    const retroPath = path.join(this.config.repoRoot, this.config.sourcePaths.retrospectives);
    if (!fs.existsSync(retroPath)) return [];

    const documents: OracleDocument[] = [];
    const files = this.getAllMarkdownFiles(retroPath);

    for (const filePath of files) {
      const content = fs.readFileSync(filePath, 'utf-8');
      const relativePath = path.relative(this.config.repoRoot, filePath);
      const docs = this.parseRetroFile(relativePath, content);
      documents.push(...docs);
    }

    console.log(`Indexed ${documents.length} retrospective documents from ${files.length} files`);
    return documents;
  }

  /**
   * Recursively get all markdown files
   */
  private getAllMarkdownFiles(dir: string): string[] {
    const files: string[] = [];
    const items = fs.readdirSync(dir);

    for (const item of items) {
      const fullPath = path.join(dir, item);
      const stat = fs.statSync(fullPath);

      if (stat.isDirectory()) {
        files.push(...this.getAllMarkdownFiles(fullPath));
      } else if (item.endsWith('.md')) {
        files.push(fullPath);
      }
    }

    return files;
  }

  /**
   * Parse retrospective markdown
   * Now reads frontmatter tags and inherits them to all chunks
   */
  private parseRetroFile(relativePath: string, content: string): OracleDocument[] {
    const now = Date.now();
    const filename = path.basename(relativePath, '.md');

    // Extract file-level tags from frontmatter
    const fileTags = this.parseFrontmatterTags(content);

    // Extract title from frontmatter or filename
    const titleMatch = content.match(/^title:\s*(.+)$/m);
    const title = titleMatch ? titleMatch[1].replace(/^#\s*/, '') : filename;

    // Clean content (remove frontmatter)
    const cleanContent = content.replace(/^---[\s\S]*?---\n*/m, '').trim();

    // Extract first meaningful line as label
    const firstLine = cleanContent.split('\n').find(l => l.trim() && !l.startsWith('#'))?.trim() || title;
    const label = firstLine.slice(0, 100) + (firstLine.length > 100 ? '...' : '');

    // Extract concepts from entire file
    const extractedConcepts = this.extractConcepts(title, cleanContent);
    const mergedConcepts = this.mergeConceptsWithTags(extractedConcepts, fileTags);

    // One document per file
    return [{
      id: `retro_${filename}`,
      type: 'retro',
      source_file: relativePath,
      content: cleanContent.slice(0, 500),
      label: label,
      concepts: mergedConcepts,
      category: classifyCategory(mergedConcepts),
      created_at: now,
      updated_at: now
    }];
  }

  /**
   * Parse frontmatter tags from markdown content
   * Supports: tags: [a, b, c] or tags: a, b, c
   */
  private parseFrontmatterTags(content: string): string[] {
    const frontmatterMatch = content.match(/^---\n([\s\S]*?)\n---/);
    if (!frontmatterMatch) return [];

    const frontmatter = frontmatterMatch[1];

    // Match tags: [tag1, tag2] or tags: tag1, tag2
    const tagsMatch = frontmatter.match(/^tags:\s*\[?([^\]\n]+)\]?/m);
    if (!tagsMatch) return [];

    return tagsMatch[1]
      .split(',')
      .map(t => t.trim().toLowerCase())
      .filter(t => t.length > 0);
  }

  /**
   * Extract concept tags from text
   * Combines keyword matching with optional file-level tags
   */
  private extractConcepts(...texts: string[]): string[] {
    const combined = texts.join(' ').toLowerCase();
    const concepts = new Set<string>();

    // Common Oracle concepts (expanded list)
    const keywords = [
      'trust', 'pattern', 'mirror', 'append', 'history', 'context',
      'delete', 'behavior', 'intention', 'decision', 'human', 'external',
      'brain', 'command', 'oracle', 'timestamp', 'immutable', 'preserve',
      // Additional keywords for better coverage
      'learn', 'memory', 'session', 'workflow', 'api', 'mcp', 'claude',
      'git', 'code', 'file', 'config', 'test', 'debug', 'error', 'fix',
      'feature', 'refactor', 'style', 'docs', 'plan', 'task', 'issue'
    ];

    for (const keyword of keywords) {
      if (combined.includes(keyword)) {
        concepts.add(keyword);
      }
    }

    return Array.from(concepts);
  }

  /**
   * Merge extracted concepts with file-level tags
   */
  private mergeConceptsWithTags(extracted: string[], fileTags: string[]): string[] {
    return [...new Set([...extracted, ...fileTags])];
  }

  /**
   * Store documents in SQLite + Chroma
   */
  private async storeDocuments(documents: OracleDocument[]): Promise<void> {
    const now = Date.now();

    // Prepare statements
    const insertMeta = this.db.prepare(`
      INSERT OR REPLACE INTO oracle_documents
      (id, type, source_file, concepts, category, created_at, updated_at, indexed_at)
      VALUES (?, ?, ?, ?, ?, ?, ?, ?)
    `);

    const insertFts = this.db.prepare(`
      INSERT OR REPLACE INTO oracle_fts (id, content, concepts)
      VALUES (?, ?, ?)
    `);

    // Prepare for Chroma
    const ids: string[] = [];
    const contents: string[] = [];
    const metadatas: any[] = [];

    for (const doc of documents) {
      // SQLite metadata
      insertMeta.run(
        doc.id,
        doc.type,
        doc.source_file,
        JSON.stringify(doc.concepts),
        doc.category || 'methodology',
        doc.created_at,
        doc.updated_at,
        now
      );

      // SQLite FTS
      insertFts.run(
        doc.id,
        doc.content,
        doc.concepts.join(' ')
      );

      // Chroma vector (metadata must be primitives, not arrays)
      ids.push(doc.id);
      contents.push(doc.content);
      metadatas.push({
        type: doc.type,
        source_file: doc.source_file,
        concepts: doc.concepts.join(','),  // Convert array to string for ChromaDB
        category: doc.category || 'methodology'
      });
    }

    // Batch insert to Chroma in chunks of 100 (skip if no client)
    if (!this.chromaClient) {
      console.log('Skipping Chroma indexing (SQLite-only mode)');
      return;
    }

    const BATCH_SIZE = 100;
    let chromaSuccess = true;

    for (let i = 0; i < ids.length; i += BATCH_SIZE) {
      const batchIds = ids.slice(i, i + BATCH_SIZE);
      const batchContents = contents.slice(i, i + BATCH_SIZE);
      const batchMetadatas = metadatas.slice(i, i + BATCH_SIZE);

      try {
        // Format as ChromaDocument array for MCP client
        const chromaDocs = batchIds.map((id, idx) => ({
          id,
          document: batchContents[idx],
          metadata: batchMetadatas[idx]
        }));
        await this.chromaClient.addDocuments(chromaDocs);
        console.log(`Chroma batch ${Math.floor(i / BATCH_SIZE) + 1}/${Math.ceil(ids.length / BATCH_SIZE)} stored`);
      } catch (error) {
        console.error(`Chroma batch failed:`, error);
        chromaSuccess = false;
      }
    }

    console.log(`Stored in SQLite${chromaSuccess ? ' + Chroma' : ' (Chroma failed)'}`);
  }

  /**
   * Close database connections
   */
  async close(): Promise<void> {
    this.db.close();
    if (this.chromaClient) {
      await this.chromaClient.close();
    }
  }
}

/**
 * CLI for running indexer
 */
const isMain = import.meta.url.endsWith('indexer.ts') || import.meta.url.endsWith('indexer.js');
if (isMain) {
  const homeDir = process.env.HOME || process.env.USERPROFILE || '/tmp';
  const repoRoot = process.env.ORACLE_REPO_ROOT || process.cwd();
  const oracleDataDir = process.env.ORACLE_DATA_DIR || path.join(homeDir, '.oracle-v2');

  const config: IndexerConfig = {
    repoRoot,
    dbPath: process.env.ORACLE_DB_PATH || path.join(oracleDataDir, 'oracle.db'),
    chromaPath: path.join(homeDir, '.chromadb'),
    sourcePaths: {
      resonance: 'ψ/memory/resonance',
      learnings: 'ψ/memory/learnings',
      retrospectives: 'ψ/memory/retrospectives'
    }
  };

  const indexer = new OracleIndexer(config);

  indexer.index()
    .then(async () => {
      console.log('Indexing complete!');
      await indexer.close();
    })
    .catch(async err => {
      console.error('Indexing failed:', err);
      await indexer.close();
      process.exit(1);
    });
}
