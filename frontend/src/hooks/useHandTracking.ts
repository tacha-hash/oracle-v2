import { useEffect, useRef, useState, useCallback } from 'react';

// MediaPipe types
declare const Hands: new (config: { locateFile: (file: string) => string }) => MediaPipeHands;
declare const Camera: new (video: HTMLVideoElement, config: { onFrame: () => Promise<void>; width: number; height: number }) => MediaPipeCamera;

interface MediaPipeHands {
  setOptions: (options: object) => void;
  onResults: (callback: (results: HandResults) => void) => void;
  send: (input: { image: HTMLVideoElement }) => Promise<void>;
}

interface MediaPipeCamera {
  start: () => void;
  stop: () => void;
}

interface HandResults {
  multiHandLandmarks?: { x: number; y: number; z: number }[][];
  multiHandedness?: { label: string }[];
}

interface HandPosition {
  x: number;
  y: number;
  confidence: number;
}

interface UseHandTrackingOptions {
  enabled?: boolean;
  onHandMove?: (pos: HandPosition) => void;
}

export function useHandTracking({
  enabled = false,
  onHandMove,
}: UseHandTrackingOptions = {}) {
  const [isReady, setIsReady] = useState(false);
  const [isTracking, setIsTracking] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const [handPosition, setHandPosition] = useState<HandPosition | null>(null);
  const [debug, setDebug] = useState<string>('Initializing...');

  const videoRef = useRef<HTMLVideoElement | null>(null);
  const cameraRef = useRef<MediaPipeCamera | null>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const onHandMoveRef = useRef(onHandMove);

  useEffect(() => {
    onHandMoveRef.current = onHandMove;
  }, [onHandMove]);

  // Load MediaPipe scripts
  useEffect(() => {
    if (!enabled) return;

    // Check if already loaded
    if (typeof window !== 'undefined' && (window as any).Hands) {
      setDebug('MediaPipe ready');
      setIsReady(true);
      return;
    }

    setDebug('Loading MediaPipe...');

    const scripts = [
      'https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js',
      'https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js',
    ];

    let loaded = 0;
    scripts.forEach(src => {
      const script = document.createElement('script');
      script.src = src;
      script.async = false; // Load in order
      script.onload = () => {
        loaded++;
        if (loaded === scripts.length) {
          setDebug('MediaPipe loaded');
          setIsReady(true);
        }
      };
      script.onerror = () => {
        setError('Failed to load MediaPipe');
        setDebug('ERROR: Load failed');
      };
      document.body.appendChild(script);
    });
  }, [enabled]);

  // Start tracking
  const startTracking = useCallback(async () => {
    if (!isReady || isTracking) return;

    try {
      setDebug('Starting camera...');

      const stream = await navigator.mediaDevices.getUserMedia({
        video: { width: 320, height: 240, facingMode: 'user' }
      });
      streamRef.current = stream;

      const video = document.createElement('video');
      video.srcObject = stream;
      video.width = 320;
      video.height = 240;
      video.autoplay = true;
      video.playsInline = true;
      video.muted = true;
      await video.play();
      videoRef.current = video;

      setDebug('Loading hand model...');

      // Initialize MediaPipe Hands (LITE model = fastest)
      const hands = new Hands({
        locateFile: (file: string) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`
      });

      hands.setOptions({
        maxNumHands: 1,
        modelComplexity: 0, // 0 = Lite (fastest), 1 = Full
        minDetectionConfidence: 0.5,
        minTrackingConfidence: 0.5
      });

      hands.onResults((results: HandResults) => {
        if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
          const landmarks = results.multiHandLandmarks[0];
          // Index finger tip = landmark 8
          const indexTip = landmarks[8];

          const pos: HandPosition = {
            x: 1 - indexTip.x, // Mirror
            y: indexTip.y,
            confidence: 1,
          };

          setHandPosition(pos);
          setDebug(`X:${(pos.x * 100).toFixed(0)}% Y:${(pos.y * 100).toFixed(0)}%`);
          onHandMoveRef.current?.(pos);
        } else {
          setHandPosition(null);
        }
      });

      // Use Camera utility for smooth frame processing
      const camera = new Camera(video, {
        onFrame: async () => {
          await hands.send({ image: video });
        },
        width: 320,
        height: 240
      });

      camera.start();
      cameraRef.current = camera;
      setIsTracking(true);
      setDebug('Tracking! Show hand');

    } catch (err) {
      const msg = err instanceof Error ? err.message : 'Camera denied';
      setError(msg);
      setDebug(`ERROR: ${msg}`);
    }
  }, [isReady, isTracking]);

  const stopTracking = useCallback(() => {
    cameraRef.current?.stop();
    cameraRef.current = null;

    streamRef.current?.getTracks().forEach(t => t.stop());
    streamRef.current = null;

    if (videoRef.current) {
      videoRef.current.srcObject = null;
      videoRef.current = null;
    }

    setIsTracking(false);
    setHandPosition(null);
    setDebug('Stopped');
  }, []);

  useEffect(() => {
    return () => stopTracking();
  }, [stopTracking]);

  return {
    isReady,
    isTracking,
    error,
    handPosition,
    debug,
    startTracking,
    stopTracking,
  };
}
